{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read sudoku images "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this project is to provide a sudoku table by analysing a image having the puzzle. It is assumed that the image contains always only one sudoku table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# read_sudoku.py\n",
    "\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "from sklearn.externals import joblib\n",
    "from skimage.feature import hog\n",
    "from sklearn.cluster import KMeans\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_args():\n",
    "    \"\"\"\"get arguments from command line\"\"\"\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('image', type=str, help='test sudoku image')\n",
    "\n",
    "    return parser.parse_args()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find Sudoku Outer Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def find_sudoku_square(image):\n",
    "    \"\"\"\"find sudoku square position and crop the image\n",
    "    input : RGB image\n",
    "    output : cropped RGB image around sudoku table\n",
    "\n",
    "    \"\"\"\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    blur = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "    thresh = cv2.adaptiveThreshold(blur,255,cv2.ADAPTIVE_THRESH_GAUSSIAN_C\n",
    "                                   ,cv2.THRESH_BINARY_INV,11,2)\n",
    "\n",
    "    ctrs, hich = cv2.findContours(thresh.copy(), cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
    "    threshod_area = int(thresh.size/5)\n",
    "\n",
    "    for ctr in ctrs:\n",
    "        area = cv2.contourArea(ctr)\n",
    "        peri = cv2.arcLength(ctr, True)\n",
    "\n",
    "        if area > threshod_area and peri > image.shape[0] + image.shape[1]:\n",
    "            rect = cv2.boundingRect(ctr)            \n",
    "            cropped_img = image[rect[1]: rect[1] + rect[3], rect[0]:rect[0] + rect[2]]           \n",
    "\n",
    "    return cropped_img\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to find the exact position of the sudoku grid in the given image, findContours function from opencv was utilised to find contours. Since the grid always have strong corners on the four vertices, the resulting contours from findContours() are expected to include the outer grid contour. The sudoku square is chosen by thresholding the contours by contour area and perimeter of it. Below shows the detected sudoku table area from a sample image. \n",
    "\n",
    "<img src=\"subdirectory/contours.png\",width=350,height=350>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Find the intersections of the grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def angle2ptr(line):\n",
    "    \"\"\"convert a polar coordinate of a line\n",
    "        to two (x,y) coordinate points\"\"\"\n",
    "\n",
    "    rho = line[0]\n",
    "    theta = line[1]\n",
    "    a = math.cos(theta)\n",
    "    b = math.sin(theta)\n",
    "    x0 = a * rho\n",
    "    y0 = b * rho\n",
    "\n",
    "    pt1 = np.array([int(x0 + 1000 * -b), int(y0 + 1000 * a)])\n",
    "    pt2 = np.array([int(x0 - 1000 * -b), int(y0 - 1000 * a)])\n",
    "\n",
    "    return pt1,pt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def perp(a):\n",
    "    \"\"\"http://www.cs.mun.ca/~rod/2500/notes/numpy-arrays/numpy-arrays.html \"\"\"\n",
    "    b = np.empty_like(a)\n",
    "    b[0] = -a[1]\n",
    "    b[1] = a[0]\n",
    "    return b\n",
    "\n",
    "\n",
    "def seg_intersect(a1,a2, b1,b2):\n",
    "    \"\"\"http://www.cs.mun.ca/~rod/2500/notes/numpy-arrays/numpy-arrays.html \"\"\"\n",
    "    da = a2-a1\n",
    "    db = b2-b1\n",
    "    dp = a1-b1\n",
    "    dap = perp(da)\n",
    "    denom = np.dot( dap, db)\n",
    "    num = np.dot( dap, dp )\n",
    "    return (num / denom.astype(float))*db + b1\n",
    "\n",
    "\n",
    "def intersection(line_a, line_b):\n",
    "    \"\"\"calculate the intersection point between two lines\n",
    "    input : polar coordinates of two lines\n",
    "    output : (x,y) intersected point\n",
    "    \"\"\"\n",
    "    pt1_a, pt2_a = angle2ptr(line_a)\n",
    "    pt1_b, pt2_b = angle2ptr(line_b)\n",
    "\n",
    "    inter_ptr = seg_intersect(pt1_a, pt2_a, pt1_b, pt2_b)\n",
    "\n",
    "    return inter_ptr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_intersections(gray):\n",
    "    \"\"\"find 100 corner points in sudoku table\n",
    "        in order to segment each cell\n",
    "    input : gray scale image\n",
    "    ouput : 100 corner points\n",
    "\n",
    "    \"\"\"\n",
    "    # Hough line detector is utilised to detect the table lines\n",
    "    blur = cv2.GaussianBlur(gray, (3, 3), 0)\n",
    "    edge = cv2.Canny(blur, threshold1=30, threshold2=90)\n",
    "    lines = cv2.HoughLines(edge, rho=3, theta=cv2.cv.CV_PI / 180, threshold=300)\n",
    "    lines = lines.reshape((lines.shape[1], lines.shape[2]))\n",
    "\n",
    "    # Detected lines are divided to horizontal and vertical lines by angle.\n",
    "    v = []\n",
    "    h = []\n",
    "    for line in lines:\n",
    "        if line[1] < cv2.cv.CV_PI / 20 or line[1] > cv2.cv.CV_PI - cv2.cv.CV_PI / 20:\n",
    "            v.append(line)\n",
    "        elif abs(line[1] - cv2.cv.CV_PI / 2) < cv2.cv.CV_PI / 20:\n",
    "            h.append(line)\n",
    "\n",
    "    # Calculate all the possible intersections\n",
    "    pts = []\n",
    "    for verti in v:\n",
    "        for horiz in h:\n",
    "            pt = intersection(verti, horiz)\n",
    "            pts.append(pt)\n",
    "\n",
    "    # Apply k-mean with 100 clusters\n",
    "    kmeans = KMeans(n_clusters=100).fit(pts)\n",
    "\n",
    "    # Cluster center points are selected to corner points on the sudoku table\n",
    "    ints = kmeans.cluster_centers_.copy()\n",
    "    ints = ints[ints[:, 1].argsort()]\n",
    "\n",
    "    return ints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function aims to find the coordinates of grid points. To achieve this, we can simply calculate the coordinates using image size and the fact that sudoku table consists of 9 x 9 cells. However, this does not guarantee the exact coordinates of each corner. Therefore, I utilised the hough line detection algorithm to find the grid lines and then, calculated all the possible intersetion points between lines. The intersection points are clustered by 100 using k-mean. The final 100 points are used to provide target images to the classifier.  \n",
    "\n",
    "<img src=\"subdirectory/hough.png\",width=350,height=350>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main(args):\n",
    "\n",
    "    file_name = args.image\n",
    "    image = cv2.imread(file_name)\n",
    "\n",
    "    image = find_sudoku_square(image)\n",
    "\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    ret, im_th = cv2.threshold(gray, 150, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "    ints = get_intersections(gray)\n",
    "\n",
    "    for ptr in ints:\n",
    "        cv2.circle(image, (int(ptr[0]), int(ptr[1])), 3, (0, 0, 255))\n",
    "\n",
    "    # Sort intersection points so that its index directly corresponds with the point location.\n",
    "    points = []\n",
    "    for i in range(10):\n",
    "        temp = ints[i*10:i*10+10,:].copy()\n",
    "        points.append(temp[temp[:,0].argsort()])\n",
    "\n",
    "    # load the classifier\n",
    "    classifier = joblib.load('../classifier/linear_svm_hog.pkl')\n",
    "\n",
    "    labels = []\n",
    "    for y in range(9):\n",
    "        for x in range(9):\n",
    "            point1 = points[y][x]\n",
    "            point2 = points[y+1][x+1]\n",
    "\n",
    "            center = (point1+point2)/2\n",
    "            # take target patch's width and height as 70% of that of the cell\n",
    "            w, h = (point2-point1)*0.7\n",
    "\n",
    "            left_top = (int(center[0] - w/2), int(center[1] - h/2))\n",
    "            right_bottom = (int(center[0] + w/2), int(center[1] + h/2))\n",
    "\n",
    "            cv2.circle(image, (int(center[0]), int(center[1])), 3, (0, 255, 0))\n",
    "            cv2.rectangle(image, left_top, right_bottom, (0,0,255),2 )\n",
    "            crop = im_th[left_top[1]:right_bottom[1], left_top[0]:right_bottom[0]]\n",
    "\n",
    "            patch = cv2.resize(crop, (28, 28), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "            # cv2.namedWindow('test', cv2.WINDOW_NORMAL)\n",
    "            # cv2.imshow('test', patch)\n",
    "            # cv2.waitKey(0)\n",
    "\n",
    "            patch = patch.reshape(1, -1)\n",
    "\n",
    "            # reject blank images\n",
    "            if np.max(patch) < 250:\n",
    "                # print '*'\n",
    "                label = '*'\n",
    "            else:\n",
    "                # intensity normalisation\n",
    "                patch = patch / 255.0 * 2 - 1\n",
    "\n",
    "                # feature extraction\n",
    "                ft = hog(patch.reshape((28, 28)), orientations=9, pixels_per_cell=(14, 14), cells_per_block=(1, 1),\n",
    "                         visualise=False)\n",
    "                label = classifier.predict(np.array([ft], 'float64'))\n",
    "\n",
    "                # label = classifier.predict(patch)\n",
    "                label = str(int(label[0]))\n",
    "\n",
    "                # print label\n",
    "            labels.append(label)\n",
    "\n",
    "    print np.array(labels).reshape(9,9)\n",
    "\n",
    "    cv2.namedWindow('test', cv2.WINDOW_NORMAL)\n",
    "    cv2.imshow('test', image)\n",
    "    cv2.waitKey(0)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    args=get_args()\n",
    "    main(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below shows the provided patch images and the result. \n",
    "<img src=\"../result/all.jpg\",width=900,height=300> \n",
    "The above results held accuracies of: 76.92%, 74.07%, 82.60%\n",
    "<img src=\"../result/all2.jpg\",width=600,height=300> \n",
    "The above results held accuracies of: 76.47%, 57.69%\n",
    "\n",
    "The tests show the results to be approximately 73.55% accurate. These can be improved by further training combination characters such as '1' and '7' as well as '0' and '9'. These are the typically confused characters which will require further fine tuning to receive greater performance.\n",
    "Furthermore, the last image proved to be the lowest ranked in the search. There are multiple reasons expected for this. The two main reasons are that the training set was based on handwritten data - which contained many different features in comparison with test data as well as being compromised by peoples handwritten habbits.\n",
    "Furthermore the thickness of the writing was quite different, the patch was not always on target within this data set and could be further improved by enlarging it or perhaps using a different centroid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
